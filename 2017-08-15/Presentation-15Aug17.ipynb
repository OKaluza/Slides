{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualisation in IPython with LavaVu\n",
    "\n",
    "## *A python module for 4D visualisation with interactive IPython notebook integration*\n",
    "\n",
    "![](combined.png)\n",
    "\n",
    "### Owen Kaluza - Monash Immersive Visualisation Platform\t\n",
    "Monash University e-Research Centre\n",
    "\n",
    "[comment]: # (7/1/2017 @ 11:15am - 12:15pm 45 Minutes 4000-5000 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Hi everyone, and thanks for coming along.  \n",
    "What I'm going to show you today is the latest state of the IPython based interactive visualisation tools that have emerged from the convergence of work on two ongoing projects in recent years ...\n",
    "\n",
    "Firstly, the project I've been involved with in some capacity since starting at Monash: working with the users of the Underworld Geodynamics simulation code to develop visualisation tools for their data,\n",
    "\n",
    "and more recently, the challenge of creating visualisations from various data sources across the university for the CAVE2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is IPython?\n",
    "\n",
    " - IPython: interactive shell combining documentation, annotation, implementation(code) and publication\n",
    " - Markdown formatted text, MathML formulae, images, video, HTML controls and components\n",
    " - Lends itself very well to use with remote resources, virtual machines and containers.\n",
    " - Used increasingly widely in research for simulations, data analysis, machine learning and general research data processing\n",
    " \n",
    " https://jupyter.org/  https://try.jupyter.org/\n",
    " \n",
    "![](jupyter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Everyone here is probably familiar with IPython but I'll give it a quick summary anyway.\n",
    "\n",
    "IPython is an interactive python shell which combines documentation, implementation and publication features into one resource by bringing python to the web browser.\n",
    " \n",
    "Python code, Markdown formatted text, mathematical formulae, images, video, HTML are all rendered in a web browser interface.\n",
    "\n",
    "All the backend hardware and software can be remote, so it's great for use on cloud resources.\n",
    " \n",
    "It's used increasingly widely in research for building of simulation models, machine learning, general research data analysis.\n",
    " \n",
    "IPython documents can be converted to plain python scripts or various other formats, including presentations such as this one.\n",
    " \n",
    "The Jupyter project is the parent project of IPython, now bringing the same features to other languages such as R and Julia.\n",
    " \n",
    "You can see a quick demo at jupyter.org, most examples make heavy use of its matplotlib integration features for creating figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![logo](LavaVu.png)\n",
    "\n",
    "#### A 3d(4d) Visualisation library : developed for advanced visualisation facilities and next-generation HPC resources\n",
    "\n",
    " - C++ backend with python interface wrapper provides a native OpenGL graphics layer to IPython\n",
    " - HTML5 GUI: usable from IPython or stand-alone via the built in web server\n",
    " - Geophysics: Underworld2 simulation code http://www.underworldcode.org/\n",
    " - CAVE2: via LavaVR, cluster rendering and CAVE2 VR mode, Volumes, 4d data, Surface Models\n",
    " - Output: still images, video animations, 3D interactive interfaces, 3D snapshots in WebGL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "LavaVu is a 3d Visualisation library and python module, written in C++ and OpenGL with a python wrapper.\n",
    "\n",
    "The python interface was built from conception to work in IPython notebooks with features that utilise the multimedia capabilities of the browser.\n",
    "\n",
    "These features can still be used from python scripts outside IPython, via the built in web server and generated static HTML pages.\n",
    "\n",
    "Currently it is being used by geosciences researchers for visualising results of the Underworld2 simulation code and in the CAVE2 for viewing time-varying data sets and volume data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Underworld: A parallel, particle-in-cell, finite element code for Geodynamics\n",
    "\n",
    "> Underworld is an open-source, particle-in-cell finite element code tuned for large-scale geodynamics simulations. \n",
    "The numerical algorithms allow the tracking of history information through the high-strain deformation associated with fluid flow.  \n",
    "The finite element mesh can be static or dynamic, but it is not constrained to move in lock-step with the evolving geometry of the fluid.  \n",
    "This hybrid approach is very well suited to complex fluids which is how the solid Earth behaves on a geological timescale.\n",
    "\n",
    "![](uw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The history of the project follows that of another project called \"gLucifer\": a framework for plotting realtime results of geophysical simulations while they run on HPC facilities within the Underworld simulation code. \n",
    "\n",
    "Underworld is a Finite-Element and Particle simulation code for Geodynamics which I've been involved with on the visualisation side since 2009.\n",
    "\n",
    "It provided a suite of vis tools called \"gLucifer\" aimed to giving instant visual output of each time step as simulations ran and offered visualisation objects tailored to the requirements of Computational Geophysicists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Dataset: Louis Moresi, from:  \n",
    "** \"Dynamics of continental accretion\" *L. Moresi, P. G. Betts, M. S. Miller & R. A. Cayley, Nature, 10 April 2014 **\n",
    "\n",
    "<video controls loop src=\"slab.mp4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Underworld2: python driven geophysics simulation http://www.underworldcode.org/  \n",
    "\n",
    ">Underworld2 is a python-friendly rework of the Underworld code base which provides a programmable and flexible front end to all the functionality of the code running in a parallel HPC environment.  \n",
    "\n",
    ">Underworld2 is integrated with the literate programming environment of the jupyter notebook system for tutorials and as a teaching tool for solid Earth geoscience.*\n",
    "\n",
    "*https://github.com/underworldcode/underworld2  \n",
    "\n",
    "![](uw2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The project has undergone a significant redevelopment and been re-released as Underworld 2.\n",
    "The underlying simulation engine is the same but the interface is completely re-worked to be driven by python and a rich set of examples and documentation built using IPython notebooks, designed to integrate with the arrival of cloud based resources.\n",
    "\n",
    "The speed of compiled C code is retained for all the key algorithms, but the interface and input files are all via python scripts with an inline visualisation system for instant feedback and plotting of simulation results.\n",
    "\n",
    "This instant visual feedback enables a \"human in the loop\" approach to analysis.\n",
    "\n",
    "The greatest gains provided by this next generation of tools simply came out of re-engineering Underworld to better leverage new tech when solving the main problems of Underworld1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Underworld2 changes:\n",
    "\n",
    "Problems addressed:\n",
    "\n",
    "1. Build and deployment: Docker\n",
    "2. Lack of flexibility and arcane XML model format: Python\n",
    "3. Difficult to learn and insufficient or out of date documentation: IPython\n",
    "4. No GUI features for visualisation: HTML5/CSS3/Javascript + IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Underworld2 docker images make getting it up and running far easier, cutting the amount of time spent supporting users with the build/configure system.\n",
    "\n",
    "Python scripts replace the XML model descriptor files and open the simulation architecture to the flexibility and power of a scripting language.\n",
    "\n",
    "IPython notebooks are helping solve the documentation issue: code and docs combined are vastly easier to keep up to date, make better teaching tools and allow automated testing to flag inconsistencies.\n",
    "\n",
    "Web technologies provide the best cross-platform graphical interfaces, now these are used to providing model building with interactive visualisation and controls in an intuitive browser interface that can be accessed while running remotely in the cloud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LavaVu: a lightweight rendering library for scientific visualisation\n",
    "\n",
    "https://github.com/okaluza/lavavu\n",
    "\n",
    "- **C++ powered** A C++ OpenGL rendering engine compiled to a binary library\n",
    "- **Python Driven** A Python interface wrapper module with underlying SWIG bindings and IPython supporting code\n",
    "- **Web GUI** - JavaScript,HTML,CSS interactive components, including WebGL output\n",
    "- **JSON data** for communication of state\n",
    "- **Numpy input** for fast loading of native data arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "I eventually rewrote the rendering component of gLucifer as a self-contained 3D scientific visualisation tool : LavaVu.\n",
    "\n",
    "gLucifer remains as the sampling and parallel data compositing layer in Underworld with its own python interface for plotting Figures utilising the LavaVu library for rendering image output.\n",
    "\n",
    "Following the pythonisation of Underworld 2, LavaVu underwent the same process, using SWIG to generate bindings and writing wrapper modules to translate from python to C++.\n",
    "\n",
    "There are now three layers to the software, the C++ rendering engine, python wrapper and Web based GUI.\n",
    "A JSON property dictionary provides communication of state data between the layers.\n",
    "\n",
    "Modifications to the state data through the browser or python script are passed through to the underlying C++ renderer.\n",
    "New vis features are easily implemented by defining and using a new property in C++, which immediately becomes available to the upper layers without having to write new wrapper functions.\n",
    "\n",
    "Numpy interfaces allow rapid processing and loading of large amounts of numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CAVE2: Challenges of Virtual Reality Visualisation\n",
    "\n",
    "#### Big data visualisation on CAVE2 and clustered display systems:\n",
    "\n",
    "- Data processing: we have to pare down large datasets that can't be rendered at interactive framerates via interactively selecting, filtering, resampling, cropping data\n",
    "- Then we can usually easily load a data set, but what next?\n",
    "- Need the ability to control/explore data by modifying vis properties interactively\n",
    "\n",
    "![](cave2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "While all this was going on, the CAVE2 was built and we now had a whole new set of visualisation challenges.\n",
    "\n",
    "The CAVE2 and other large display systems provide screen resolution to match huge data sets - more pixels provide more visual bandwidth but and also require more raw computing power in the form of a cluster.\n",
    "\n",
    "So the real challenges are in software... \n",
    "\n",
    "For initial data exploration, the data is often too large and visually incomprehensible for VR use without significant post-processing and reduction.\n",
    "\n",
    "Virtual Reality and clustered display systems rely on custom tools to interact with data, and high frame-rates for interactive viewing. Desktop software just doesn't translate well.\n",
    "\n",
    "When used with well designed and carefully crafted visualisations targetting these systems we can achieve compelling tools for analysis of visual spatial data and wow-factor in communication of research for outreach.\n",
    "\n",
    "But most researchers already have their favourite software tools, for visualisation these are often all-in-one desktop applications that can't be used on a cluster based system like the CAVE2 or easily integrated into a more flexible pipeline.\n",
    "\n",
    "The power of python is in the way it encourages the approach of using many smaller tools to put build a custom work-flow and this can be a far more flexible, powerful and agile way of doing things.\n",
    "\n",
    "Fortunately IPython is making this approach much more accessible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### How can we engage researchers and improve research use of the facility?  \n",
    "\n",
    "Show how they can use it to:\n",
    "\n",
    "1. Communicate their research to others (wow-factor for collaboration/outreach/funding)\n",
    "2. Gain increases in understanding of their data or increased efficiency in analysing and processing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It's hard to get people to leave their desks and go into a visualisation facility to work unless it is of clear advantage to them to do so.\n",
    "\n",
    "We have had success with the first point above, the second is more difficult.\n",
    "\n",
    "If we can offer tools that have potential to be used outside the CAVE2 on the desktop through an easy to use and already popular enviroment such as IPython and they can bring something useful to the workflow, from there bringing the data and workflow into the CAVE2 is an easy matter.\n",
    "\n",
    "So ideally, researchers will be able to access, upload, visualise and adjust the visualisation parameters of their data in a browser interface before ever leaving their desk, then share these results for collaboration using the same familiar tools we have developed. This has been an ongoing effort by all of us at MIVP and I see LavaVu as one piece of the puzzle in making this a reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why LavaVu?\n",
    "What it does well:\n",
    "- Use with the vast library of tools available in python\n",
    "- Remote rendering and graphics on HPC systems while simulations are running using Mesa (software OpenGL)\n",
    "- Server side render, client side control - via built in HTTP server and IPython.\n",
    "- Correctly render transparency in large point swarms and surfaces\n",
    "- Combined vis elements: volume/surface/point/line\n",
    "![](particles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So why use this library? I'll run through some of it's strong points:\n",
    "\n",
    "Python and Numpy support.\n",
    "\n",
    "It was built to work with HPC clusters without GPU hardware, so the ability to produce graphics on CPU only systems and serve images is well tested.\n",
    "This allows scripted visualisation tasks to run without display hardware. \n",
    "\n",
    "In general it's great for tasks where the data needs to stay on a remote server due to size, or to share for collaborative work.\n",
    "\n",
    "It has the ability to render transparency correctly for large point swarms and surfaces, requiring sorting all elements and batch rendering, many scene-graph based renderers only support this for individual models rather than the entire scene.\n",
    "\n",
    "It provides volume rendering with surfaces, point and line rendering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why LavaVu?\n",
    "What it does well (cont.):\n",
    "- Built for handling time-varying 4D data sets: simulation data\n",
    "- IPython notebooks: analyse / visualise / process with IPython, instant vis results as part of the analysis workflow.\n",
    "- CAVE2 and VR: pathway direct to CAVE2 with our VR module, LavaVR \n",
    "- Scriptable image and video output, save and restore state, record and checkpoint stages of vis workflow\n",
    "- Scriptable custom HTML5 GUI components\n",
    "![](foot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Intrinsically supports 4D data, particularly simulation data, with multiple levels of caching in RAM or GPU ram that can be enabled or disabled.\n",
    "\n",
    "IPython notebook integration and custom user interfaces, using notebooks, vis becomes an intergrated part of the analysis workflow.\n",
    " \n",
    "VR support: any visualisations created using this library can be loaded straight into the CAVE2 in our VR module, LavaVR to run in the CAVE2.\n",
    "\n",
    "Completely scriptable including image and video output, state save and restore so once desired images/videos are created they can be saved and re-rendered easily.\n",
    "\n",
    "There is no standard GUI but scriptable custom GUI components so you can have as much or little GUI control as you like. The down side is you need to work from examples to build and use these interfaces as they can be hard to implement just from API docs.\n",
    "\n",
    "For a plotting tool to create data vis, charts, or 2d graphs, there are definitely better choices.\n",
    "\n",
    "Consider it if the goal is scientific 3D vis: that is to render complex 3D and 4D data in order to better visually analyse it and building a workflow using python or IPython is a drawcard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to get it?\n",
    "\n",
    "Github:  \n",
    "https://github.com/okaluza/lavavu\n",
    "\n",
    "Instructions for building on Mac/Linux, including with IPython in the wiki:  \n",
    "https://github.com/okaluza/lavavu/wiki\n",
    "\n",
    "Windows build: out of date due to lack of demand\n",
    "\n",
    "Docker: (CPU and GPU versions to come)\n",
    "https://hub.docker.com/r/lavavu/latest/\n",
    "\n",
    "Docker run on Linux with GPU access (open-source drivers only):\n",
    "```\n",
    "xhost +\n",
    "docker run -v $HOME:/workspace/home -p 8888:8888 --volume=/tmp/.X11-unix:/tmp/.X11-unix --device=/dev/dri:/dev/dri --env=\"DISPLAY\" lavavu/latest:v1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It's all open-source and the github repository contains simple instructions to build the code from source on Unix based systems\n",
    "\n",
    "Complete instructions including installing IPython are also found on the github wiki.\n",
    "There are very few required dependencies, mainly only those needed by Jupyter.\n",
    "\n",
    "I used to do a windows build but it has fallen by the wayside due to lack of demand. If anyone requests I'd happily update it.\n",
    "\n",
    "I've also recently built a docker image, due to the use of OpenGL it can be trickier to get going with GPU support, requiring permission to use the display.\n",
    "\n",
    "A CPU only docker image that uses the Mesa llvmpipe OpenGL driver will run without these issues and will render using all CPU cores, it only really falls down when you try and use it for volume rendering tasks (dropping below 1 frame per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to use it?\n",
    "\n",
    "Tutorials/Examples:\n",
    "- [Surface Mesh Models](http://localhost:8888/notebooks/LavaVu/notebooks/SurfaceModels.ipynb)\n",
    "- [Simple Volume Rendering](http://localhost:8888/notebooks/LavaVu/notebooks/Volume.ipynb)\n",
    "- [Particles](http://localhost:8888/notebooks/LavaVu/notebooks/Particles.ipynb)\n",
    "- [HDF5 Loading](http://localhost:8888/notebooks/LavaVu/notebooks/ViewHDF5.ipynb)\n",
    "\n",
    "Other examples from CAVE2 projects:\n",
    "- [Digital Elevation Model : geoTIFF](http://localhost:8888/notebooks/examples/LoadDEM.ipynb)\n",
    "- [Volume - Rabbit Lungs](http://localhost:8888/notebooks/examples/Volume-Rabbit.ipynb)\n",
    "- [Carbon Sequestration](http://localhost:8888/notebooks/Projects/CO2/Carbon.ipynb)\n",
    "\n",
    "Underworld simulation models:\n",
    "- [Rayleigh Taylor Benchmark](http://localhost:8888/notebooks/examples/1_06_Rayleigh_Taylor.ipynb)\n",
    "- [Slab Subduction 2d](http://localhost:8888/notebooks/examples/1_07_SlabSubduction.ipynb)\n",
    "- [OzBench Subduction 3d](http://localhost:8888/notebooks/examples/OzBenchEtAl-2008.ipynb)\n",
    "\n",
    "Underworld model visualisation:\n",
    "- [Dynamics of continental accretion](http://localhost:8888/notebooks/examples/SlabSubductionHighRes.ipynb)\n",
    "- [DEM Topography to Mesh](http://localhost:8888/notebooks/examples/InitialTopography/Initial_Topography_InlineVis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "I'll run through a few examples to show how it works.\n",
    "\n",
    "Slow run through: particles\n",
    "\n",
    "Faster:\n",
    "\n",
    "- Surface\n",
    "- Rabbit\n",
    "- DEM\n",
    "- Carbon\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "Built-in support for data files includes:\n",
    "\n",
    " - Meshes in Wavefront OBJ format\n",
    " - Raw volume data\n",
    " - TIFF image stacks or wildcard JPG/PNG images to load as volumes\n",
    " - DEM height maps\n",
    " - GLDB (vis database format that uses SQLite3, designed for gLucifer/Underworld to store time-varying Geophysical simulation data - models can be exported from LavaVu to this format to package them neatly in a single file)\n",
    "\n",
    "Support for further formats is provided with example python scripts that process the data from python and pass it to LavaVu, such as:\n",
    "\n",
    " - Point clouds in text and binary formats (X,Y,Z,R,G,B etc)\n",
    " - Tecplot\n",
    " - HDF5\n",
    "\n",
    "Documentation for all the properties and commands can be found on github, here: http://github.com/OKaluza/LavaVu/wiki\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusions\n",
    "- Convergence\n",
    "- One puzzle piece in e-Research workflows\n",
    "- Future work?\n",
    "\n",
    "#### Thanks\n",
    "- MeRC\n",
    "- My colleagues at MIVP\n",
    "- The Underworld 2 team and researchers\n",
    "\n",
    "![](cave2rabbit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So to sum up, it's been an interesting journey so far trying to bring these multiple projects together.\n",
    "\n",
    "One of our aims at MIVP now is instead of being purely an end-point for visualisation, if our development efforts can provide useful additions to the vis work-flow outside of our facilities, then these facilities become an effortless addition to that work-flow that researchers can easily choose to utilise. \n",
    "\n",
    "With flexible and modular vis tools accessible from the widely used python ecosystem, that are usable remotely on cloud resources, there is more potential to integrate with other e-Research tools and resources become part of an overall flexible analysis and visualisation pipeline.\n",
    "\n",
    "If we succeed at this software based challenge, then we can much better utilise the hardware provided by our current and future high-end vis and VR facilities as they will seamlessly become an optional part of a scientific workflow going from Capture, Storage, Collaboration, Analysis & Visualisation through to Publication and Communication.\n",
    "\n",
    "The work undertaken is already being utilised succesfully by researchers in the Geophysics domain, and greatly aids with our work in the CAVE2 and recent development efforts have been concentrated on attempting to improve accessibility to the wider community.\n",
    "\n",
    "It's been a little bit more ambitious and time-consuming than I realised however, to try and polish some of these ideas into a finished product from prototypes, so from here it's a question of seeing if it proves worthwhile.\n",
    "\n",
    "Our future goals include getting this stuff running in head mounted VR and integrating some of the various development efforts at MIVP together.\n",
    "\n",
    "Thank you for listening, and I'm happy to answer any questions."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
