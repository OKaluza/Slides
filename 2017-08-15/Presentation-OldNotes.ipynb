{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LavaVu: A Python/IPython 4D visualisation framework with remote/headless rendering capability\n",
    "### Visualisation tools developed for use on Cave2 and Cloud/HPC Technology\n",
    "\n",
    "### Owen Kaluza\n",
    "## Monash Immersive Visualisation Platform\t\n",
    "Monash University\n",
    "Monash e-Research Centre (MeRC)\n",
    "Monash Immersive Visualisation Platform (MIVP)\n",
    "\n",
    "[comment]: # (7/1/2017 @ 11:15am - 12:15pm 45 Minutes 4000-5000 words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURPOSE OF TALK\n",
    " - Introduce LavaVu IPython library, why developed, current users (What: Vis library: C++ with python interface, connects a native OpenGL based vis layer with a browser based interface in IPython)\n",
    " - Explain strengths/weaknesses: where it excels is plotting time-varying 3D data sets, does not have the breadth of features of large general purpose vis tools (paraview/visit) for working with huge data sets, you have to use python/numpy to subsample as necessary to work with available resources. No pre-packaged GUI, but the custom GUI components are very powerful for creating analysis and collaboration/presentation/education tools. Interactive server-side rendering within IPython notebook! What not to use for: anything beyond simple 2D plots: matplotlib/plotly etc do this better, I am not going to try and compete there. \n",
    " - Data Model: rendering primitives (point/line/tris/volumes) -> rendering elements -> (all primitives + vectors/tracers/shapes/surfaces/labels) -> [...TIME STEPS...] -> OBJECTS (properties) -> VIEWS  (properties) -> FIGURES (properties) -> MODELS -> VIEWER\n",
    " - Examples of visualisation workflows (load and inspect data via numpy interface, types of plots, analyse data with interactive controls, share data in a collaborative environment (Notebook server), produce scripted images and videos for publication/presentation/sharing), running in containers and on Nectar. (MODELS: Underworld (sim + Romain's terrain mesh via gdal), Particle sim with Points+Vectors+Tracers, Volume (Foot/Rabbit lungs), Mesh (Kookaburra)\n",
    " - Where next? This project has so far been mostly a one man show, and I'm trying to keep maintainence burden under control by narrowing the focus to be really good at a few things rather than mediocre at everything... want to get the word out there because I know a lot of researchers are using IPython now and nearly all the vis tools are quite similar (targeted more to the Data Vis community) and mostly using client side graphics (WebGL)\n",
    "\n",
    "\n",
    " - IPython: combines documentation, annotation, implementation and publication aspects in one document\n",
    " - Markdown formatted text, MathML formulae, images, video, HTML controls and components\n",
    " - Used more and more widely in research for building of simulation models, data analysis and research, machine learning etc\n",
    " \n",
    "Vis for CAVEs and large displays: \n",
    "- We can usually easily load a data set, but what then:\n",
    "- Ability to control/explore data by modifying vis properties\n",
    "- Ability to pare down large datasets that could not be rendered at interactive framerates via interactively selecting, filtering, resampling, cropping data\n",
    "\n",
    "Similar:\n",
    "Bokeh (more data vis d3d style, server side), VisPy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TITLE\n",
    "\n",
    "My name is Owen Kaluza, I am employed by the Immersive Visualisation Platform as a Visualisation Software Specialist. \n",
    "My background is in Computer Science with an emphasis on 3D graphics, parallel and GPU programming. \n",
    "My two ongoing projects in recent years have been developing visualisation software for the CAVE2 and the users of the Underworld Geodynamics simulation code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> OUTLINE \n",
    "\n",
    "**(What I'll talk about)**\n",
    "The CAVE2, our ultra-scale immersive visualisation facility, and the applications and challenges using this technology presents.\n",
    "\n",
    "Then I'll present some tools we've developed for Geophysics research, how visualisation is approached, how HPC resources are utilised and how cloud and other technologies has changed this.\n",
    "\n",
    "Finally I'll go into how the combination of work from these areas has converged, leading to a set of general visualisation tools that can be used to help analyse visualisations of large scientific datasets and build work-flows, especially on remote and cloud based infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAVE2 Vis Goals\n",
    "When we first opened the facility, a lot of our time was consumed just enabling visualisation of common model data formats in a new environment.\n",
    "Much of this was simply conversion of data and pre-processing to meet the requirements of existing software we had running on the CAVE2 cluster.\n",
    "Over time, we've streamlined this process and, as shown, developed some custom tools that expose the power of the facility by interactive control over data visualised and vis parameters.\n",
    "\n",
    "Moving forward, what weâ€™d really like to say is we've helped directly enable new discoveries by using immersive vis, but something we increasingly try to achieve in development efforts is also making sure the tools we create are useful outside these facilities where possible\n",
    "\n",
    "- For exploring and analysing data: better interaction with 3D objects in virtual space is an active area of research\n",
    "- and particularly, looking for new research driven applications of this technology: tools for exploration and analysis of data in new ways is the priority, not just seeing it on a big screen in 3D\n",
    "\n",
    "There are problems of course, people don't want to leave their desks or labs and go into a visualisation facility to do work unless the results are very compelling. This requires effectively communicating the possibilities and engaging researchers. To really take advantage of immersive visualisation facilities takes time and collaborative development of new software tools. \n",
    "Quality software to utilise new technology is nearly always running behind the hardware by some years and at research institutions we often run out of funding before being able to do the remaining 80% of a software development cycle that creates a polished finish product by commercial standard.\n",
    "VR is only now becoming successfully commercialised and with increasing development efforts, the tools are becoming better. Cluster based rendering is too unweildy and esoteric to reach the mainstream any time soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big data\n",
    "Single research data sets we deal with for visualisation don't usually qualify as truly \"Big Data\" problems, by the standards of Google etc (ie: they can be stored on a single machine)\n",
    " \n",
    "However, research data collectively is constantly growing in size\n",
    "Once a researcher has accumulated data from enough experiments, even smaller collections become unwieldy and managing them or querying the aggregate easily qualifies as a big data problem.\n",
    "\n",
    "Techniques developed from the big data sphere are proving useful, even on smaller data sets. Generating metadata, machine learning and data mining, interactive vis and analysis with tools like Jupyter/IPython which can run on remote hardware.\n",
    "\n",
    "That said, there is still a lot of improvement in how we handle scientific data sets. Researchers are (understandably) often reluctant to share their data, especially before they have published results. \n",
    "Afterwards it can end up forgotten, archived in some inaccessible private data store, worst case: a portable drive on a shelf somewhere!\n",
    "There is still a long way to go before we can more openly collect and store data making it available for future research. Taking advantage of data science techniques requires us to be aware of available data and collect metadata to help catalogue it.\n",
    "\n",
    "Science funding is competitive and collecting data can be a difficult, time-consuming and expensive first step for any research. There are already a lot of publicly available research but I anticipate we'll see this increasing exponentially, to the point perhaps, that even more collection will be automated, as we are seeing with genetic sequencing. \n",
    "Obviously coming up with new data sets and original techniques of sampling data will continue at the cutting edge, but the types of data collection for which a future requirement is predictable could be automated if the cost of gathering/processing becomes cheap enough, such as vast arrays of autonomous sensors.\n",
    "Many more scientists in the future will be able perform research and make new discoveries without having to gather their own new data sets, and data science techniques will be increasingly invaluable.\n",
    "The originality will come from the selection of data, for example, the how digitisation of paper archives has already changed the practice of history, enabling vast, previously hidden resources to be accessed by researchers anywhere in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling large data visualisation:\n",
    "\n",
    "With the CAVE2 and other large display systems we have screen resolution to match the data, this aids us in comprehending larger data sets. More pixels provide more visual bandwidth ... but also require more computing power to process.\n",
    "However the real challenges are in the software...\n",
    "Most researchers already have their favourite software tools, for visualisation these are, more often than not, all-in-one applications that must run on a desktop operating system and can't be used on a cluster based system like the CAVE2 or easily integrated into a more flexible pipeline.\n",
    "Instead of these monolithic applications, the unix style approach of using many smaller tools to put build your own custom work-flow can be a far more flexible, powerful and agile way of doing things if the tools are available and the complexity is not outside the skill domain of the researcher. \n",
    "Increasingly these kind of tools are becoming more accessible (via python etc) and increasingly the power to build such custom pipelines is within reach of more and more researchers - not just computer scientists and computational experts who are comfortable with command line tools and compiled languages. The learning curve is flattening and usability increasing (Jupyter notebooks etc). \n",
    "\n",
    "Currently, Virtual Reality and clustered display systems provide compelling results for well designed and carefully crafted visualisations, but these require custom tools to interact with data, and very high frame-rates for interactive viewing. \n",
    "Sometimes this is far from ideal for initial data exploration, the data is often too large and raw without significant post-processing and reduction...\n",
    "Results can be fantastic for final analysis of visual outputs from a processing pipeline or presentation/communication of data for outreach and collaboration. \n",
    "This comes from my experience with VR in a large cluster-based display system, but the challenges for head-mounted display based VR are similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underworld: A parallel, particle-in-cell, finite element code for Geodynamics\n",
    "\n",
    "http://www.underworldcode.org/\n",
    "https://github.com/underworldcode/underworld2\n",
    "\n",
    ">Underworld is an open-source, particle-in-cell finite element code tuned for large-scale geodynamics simulations. The numerical algorithms allow the tracking of history information through the high-strain deformation associated with fluid flow (for example, transport of the stress tensor in a viscoelastic, convecting medium, or the advection of fine-scale damage parameters by the large-scale flow). The finite element mesh can be static or dynamic, but it is not constrained to move in lock-step with the evolving geometry of the fluid. This hybrid approach is very well suited to complex fluids which is how the solid Earth behaves on a geological timescale.\n",
    "\n",
    "\n",
    "Underworld is a geodynamics simulation code started at Monash University, I have been involved with the visualisation and analysis side of the project since 2009.\n",
    "There is a built in set of visualisation tools called \"gLucifer\" which aimed to provide instant visual feedback as simulations ran and visualisation tools tailored to the requirements of Geophysicists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underworld2: python driven simulation, visualisation & analysis\n",
    "\n",
    ">Underworld2 is a python-friendly rework of the Underworld code base which provides a programmable and flexible front end to all the functionality of the code running in a parallel HPC environment. This gives significant advantages to the user, with access to the power of python libraries for setup of complex problems, analysis at runtime, problem steering, and coupling of multiple problems. Underworld2 is integrated with the literate programming environment of the jupyter notebook system for tutorials and as a teaching tool for solid Earth geoscience.\n",
    "\n",
    "> Underworld2 builds upon the StGermain framework described in Quenette et al, (2007). This provides the essential infrastructure to manage i/o, meshes, particle swarms, finite element operations, in a parallel (domain decomposition, message passing) environment. The numerical solvers are based around the PETSc software suite which focuses on delivering good parallel scalability (up to thousands-of-cores). Our experience to date shows good scalability for thermal problems to 2000+ cores, but for the relatively memory-intensive dynamic simulations, we have a drop-off in scaling at 500+ cores.\n",
    "> The Underworld2 development team is based in Melbourne, Australia at the University of Melbourne and at Monash University led by Louis Moresi.\n",
    "\n",
    "The project has recently undergone a significant (and long overdue) redevelopment and released as Underworld 2.\n",
    "The underlying simulation engine is the same but interface is completely re-worked to be driven by python scripts and a set of examples and documentation build using Jupyter IPython notebooks.\n",
    "\n",
    "We are finding, perhaps later than many others, that this is a very powerful architecture.\n",
    "\n",
    " - Python interface with underlying compiled C/C++ libraries for speed, examples and tutorials provided in Jupyter notebooks \n",
    " - Inline visualisation system for instant feedback and plotting of simulation results and calculations - enabling \"human in the loop\" searching for patterns / errors using our huge bandwidth visual processing\n",
    "\n",
    "Over time, the gLucifer rendering engine was made increasingly modular and independent and split of from the rest of the code, it is now a self-contained 3D scientific visualisation tool, which we called LavaVu. gLucifer remains as the set of sampling and analysis tools within underworld that provide data to LavaVu for rendering and the python interface to this.\n",
    "\n",
    " - LavaVu: a lightweight rendering tool for scientific and data visualisation https://github.com/okaluza/lavavu\n",
    "\n",
    "Like Underworld 2, LavaVu is python driven, allowing access to the vast suite of tools available in the python ecosystem to process data prior to visualisation with the ability to see the results of data manipulation in an instant.\n",
    "Output can be in the form of static images, video animations, 3D interactive views and 3D snapshots in WebGL.\n",
    "\n",
    "> Trinity: C++ powered, Python Driven, Web for user interaction\n",
    "> SLIDE? showing 3 elements, tied together with JSON data\n",
    "\n",
    "The big advances provided by this next generation of tools are consequences of our efforts in re-engineering aspects of the frameworks to better use the right tool for the job.\n",
    "The core of our existing code was solid, using C and C++ ensured they were fast and efficient. The main inadequacies were:\n",
    "\n",
    "- difficulty getting the code compiled on many and varied systems from desktops to clusters\n",
    "- ease of customisation and expansion (the plugin system required writing and then compiling code in the underlying C framework)\n",
    "- model building: required editing XML files (Not having to edit XML should be a universal human right)\n",
    "- user interaction: no interactive GUI features were available at all for building and editing models or visualisation\n",
    "\n",
    "Docker containers have largely solved the first problem for us.: We now provide docker images for Underworld2 which makes getting up and running super easy, it has drastically reduced the amount of time we have to spend supporting users with the build/configure system. Docker support on OS X and Windows is also getting better every day.\n",
    "\n",
    "Python provided the solution to the next two points, replacing the XML model descriptor files with python scripts and opening up the full simulation architecture to the flexibility and power of a scripting language.\n",
    "\n",
    "IPython (Jupyter notebooks) and HTML5 technology provided the solution to the final point, allowing model building combined with interactive visualisation and GUI controls in a friendly, browser interface. Using web technologies also avoids all the pain of making GUI software work cross-platform as well as providing the perfect way of utilising remote hardware resources such as cloud instances. \n",
    "\n",
    "The 3 elements are tied together by JSON data storage, the ubiquitous JavaScript Object notation is readily supported in python and easily accessed in C++ by use of a library. \n",
    "Modifications to this JSON state are done through the browser or python script and passed through to the underlying C/C++ renderer.\n",
    "New vis features are enabled by accessing a new property and thus are instantly available to Python and JavaScript interfaces without having to write new wrapper code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LavaVu, LavaVR : python driven visualisation tools for remote and cluster visualisation\n",
    "\n",
    "Back while I was telling you about our CAVE2 system, I mentioned the challenges caused by a cluster driven display and the requirement to use bespoke software, as very little existing software provides support for running on a system of this nature. \n",
    "We found that even tools like Paraview, which are built to run on clusters, were far too limited in frame-rate when displaying such high resolution output for any useful interactive work in VR.\n",
    "\n",
    "The side-effect of this is our team have developed an advanced set of visualisation tools to display and work with just about any data source we get our hands on, optimised to get frame-rates necessary for interactive VR. \n",
    "One of those is a virtual-reality and cluster-enabled version of LavaVu called LavaVR.\n",
    "\n",
    "LavaVR uses the previously mentioned Omeglib library developed at UIC, which allows LavaVu to run in the CAVE2 and other VR systems.\n",
    "\n",
    "We can load basic common data types with the standard frameworks running on our vis cluster (Omegalib, CalVR etc) but it's always easier to tweak or add a custom feature to your own well known code base, so over time this led to increasing the capabilities and power of our in-house rendering tools.\n",
    "\n",
    "Of-course we have the usual problems re-inventing the wheel and maintenance burden of in-house tools... \n",
    "We don't have the time or funding to implement all features of a specialist visualisation package tailored to a particular type of data, and the software is not familiar to the researchers who provide the data and thus our workload is increased by having to maintain one-off features, process data for researchers, assist them with using the tools in the VR facilities.\n",
    "Researchers are discouraged from using the facility as they can't use their own tools and can't be self-contained while using it.\n",
    "\n",
    "To address some of these problem, we are attempting a solution providing a set of tools on cloud based services that allow researchers to access or upload, visualise and adjust the visualisation parameters of their data before ever leaving their desk. \n",
    "Data stored on our fast data storage services will be accessed through the MyTardis portal, loaded in a visualisation tool in-browser, providing a way to prepare data for use in the facility that will appear exactly as shown.\n",
    "The same software provides the web based visualisations via WebGL and/or Remote Server-Side visualisation as the immersive VR visualisation in the CAVE2.\n",
    "\n",
    "The advantages of this approach are numerous:\n",
    "\n",
    " - Data stored on storage facilities connected to cloud instances can be accessed over internal networks at high speed without data unnecessary transfer overheads.\n",
    " - Capabilities of the system are shown immediately and users know what to expect from visualisation tools.\n",
    " - Familiarity gained with the tools available allows researchers to drive their own usage\n",
    " - Feedback on required features can lead to new features being implemented when required without repeated visits to facilities\n",
    " - Final results of visualisation are stored and can be accessed using the same online tools and shared via WebGL or static images.\n",
    "\n",
    "There are also a number of great benefits of integration with the python ecosystem and IPython notebooks in particular:\n",
    "\n",
    " - Python comes with a huge software library and is the tool of choice for big data analytics\n",
    " - Our tools become just one of many available, rather than having to write a full desktop application with hundreds of features, you can concentrate on being good at a few things and farm everything else out to other libraries. Researchers can use these other tools to fill gaps in the functionality our software provides.\n",
    " - IPython is a great learning environment, you can start with examples and work interactively, instantly seeing what the effects of your actions are. Don't get me wrong, I love command line tools, but working in the browser with inline images is a great tool for instant visual analysis, rapid prototyping, experimentation and modelling, and there are plenty of researchers who don't want to work with command line tools.\n",
    "\n",
    "There are also some challenges: now we're in the world of interactive python, we have to change our mindset.\n",
    "These applications were originally developed in the C/C++ compiled software world where we had to think carefully before adding a dependency, especially if that code had to be built on a cluster without ability to install packages... sometimes it is was easy to fall into a trap: it was often a lot less painful at first to \"build your own\" functionality rather than requiring another library to be installed just for a few small functions. Getting new dependencies to work across the multiple esoteric cluster systems we supported could be really difficult... This of course comes with a debt of maintenance down the track!\n",
    "\n",
    "Now we have easy access to a huge set of ready to use libraries, a great deal of this remaining cruft can go... reducing the maintenance burden by being able to \"sub-contract\" functionality to other libraries so much more easily.\n",
    "The challenge is to really try and identify what our software does well and stick to working on that, anything else should be cut out and replaced with external packages.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### MORE ON IPython: Single image output, Interactive vis output, WebGL output, GUI interactive controls, multi-target interface generation [IPython, HTML, VR (Omegalib)] JSON property management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LavaVu: A quick feature run-through / demo\n",
    "(Move this to a notebook)\n",
    "First import the library, then you'll want to create a viewer, the viewer object returned can be used to set global vis properties and settings so save it.\n",
    "> import lavavu\n",
    "> lv = lavavu.Viewer()\n",
    "\n",
    "Loading a data set from a pre-supported type is easy, pass in the filename and it will be loaded based on extension, a vis object is returned that can be used to set properties that apply to this data\n",
    "> obj = lv.file('imagestack.tif')\n",
    "\n",
    "One we have some data loaded, lets take a look, display() produces an inline image of the current visualisation (if not running in IPython it will be saved to disk instead):\n",
    "> lv.display()\n",
    "\n",
    "Built-in support for data files includes:\n",
    "\n",
    " - Meshes in Wavefront OBJ format\n",
    " - Raw volume data\n",
    " - TIFF image stacks or wildcard JPG/PNG images to load as volumes\n",
    " - DEM height maps\n",
    " - GLDB (our native vis database format that uses SQLite3, designed for gLucifer/Underworld to store time-varying Geophysical simulation data)\n",
    "\n",
    "Support for further formats is provided with example python scripts that process the data from python and pass it to LavaVu, such as:\n",
    "\n",
    " - Point clouds in text and binary formats (X,Y,Z,R,G,B etc)\n",
    " - Tecplot\n",
    " - HDF5\n",
    "\n",
    "To directly load data, for example a point cloud, first you create a vis object of the appropriate type, passing it the data:\n",
    "> data = myCustomLoader.load('somefile.xyz')\n",
    "> myobj = lv.points(data)\n",
    "\n",
    "Vis objects can hold multiple types of data, the convenience functions (eg: points(), triangles() ) simply load data of the required type and create the object in one call. \n",
    "\n",
    "This time, instead of plotting a static image, lets load an interactive view:\n",
    "> lv.window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property setting:\n",
    "\n",
    "Properties can be applied to the Viewer object which will take effect globally:\n",
    "\n",
    "> lv[\"background\"] = \"grey\"\n",
    "\n",
    "Or, applied to a vis object, effecting only that object:\n",
    "\n",
    "> points[\"pointsize\"] = 10\n",
    "\n",
    "Documentation for all the properties can currently be found on github, here: http://github.com/OKaluza/LavaVu/wiki\n",
    "Work is in progress to use python docstrings to make property documentation available inline in IPython.\n",
    "\n",
    "We can also add some interactive controls:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive controls\n",
    "\n",
    "Interactive controls can be created and displayed individually or added to a control panel and displayed together with a window.\n",
    "\n",
    "If created on their own, an active viewer window is required for the changes to take effect, (lv.window())\n",
    "\n",
    "> bgcolour = lv.control.Range(...)\n",
    "> bgcolour.show()\n",
    "\n",
    "Using a Panel:\n",
    "\n",
    "> panel = lv.control.Panel()\n",
    "> .. GET FROM CARBON\n",
    "\n",
    "The python module creating these controls is now targetting the IPython notebook environment, but is flexible enough to also create a standalone HTML interface that can be used if running without IPython or a 3D VR enabled menu script usable from LavaVR in Omegalib.\n",
    "The idea is that the user can write the desired interface once and have the same functionality wherever the data is displayed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "So to sum up, it's been a challenging and interesting journey trying to bring these multiple projects together.\n",
    "\n",
    "We've made some nice progress but there's still a ways to see if any of this makes it out into the wider community.\n",
    "\n",
    "The way we are thinking now is instead of being an end-point for visualisation at MIVP, we want to insert ourselves into the work-flow by providing a useful product outside of our facilities.\n",
    "\n",
    "If we can create flexible and modular vis tools from python, that are usable remotely on cloud resources, this should be able to integrate with other tools and become part of an overall flexible analysis and visualisation pipeline.\n",
    "\n",
    "If we can succeed at this software based challenge, then we can much better utilise the hardware provided by our current and future high-end vis and VR facilities as they will seamlessly become an optional part of a scientific workflow going from Capture, Storage, Collaboration, Analysis & Visualisation through to Publication and Communication.\n",
    "\n",
    "Thank you for listening, and I'm happy to answer any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
